{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Exercise 4 (Handling complex images)",
      "provenance": [],
      "authorship_tag": "ABX9TyNRvgVqBjsj88I/rc03/Tgp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hritikvalluvar/Introduction-to-TensorFlow-for-Artificial-Intelligence-Machine-Learning-and-Deep-Learning/blob/master/Exercise_4_(Handling_complex_images).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRL_HVhqujAv",
        "colab_type": "text"
      },
      "source": [
        "# **Problem**\n",
        "Below is code with a link to a happy or sad dataset which contains 80 images, 40 happy and 40 sad. Create a convolutional neural network that trains to 100% accuracy on these images, which cancels training upon hitting training accuracy of >.999\n",
        "\n",
        "Hint -- it will work best with 3 convolutional layers.\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWtr2iPuuvlL",
        "colab_type": "text"
      },
      "source": [
        "# **Importing TensorFlow**\n",
        "\n",
        "\n",
        "* The following python code will use the OS library to use Operating System libraries, giving you access to the file system, and the zipfile library allowing you to unzip the data.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyWIYhwUs6XZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import zipfile\n",
        " \n",
        "DESIRED_ACCURACY = 0.999\n",
        " \n",
        "!wget --no-check-certificate \\\n",
        "    \"https://storage.googleapis.com/laurencemoroney-blog.appspot.com/happy-or-sad.zip\" \\\n",
        "    -O \"/tmp/happy-or-sad.zip\"\n",
        " \n",
        "zip_ref = zipfile.ZipFile(\"/tmp/happy-or-sad.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp/h-or-s\")\n",
        "zip_ref.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_QWBVsesyRv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_happy_sad_model():\n",
        "\n",
        "    # Setting Callback for 99.9% accuracy\n",
        "    class myCallback(tf.keras.callbacks.Callback):\n",
        "      def on_epoch_end(self, epoch, logs={}):\n",
        "        if(logs.get('acc')>DESIRED_ACCURACY):\n",
        "          print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "          self.model.stop_training = True\n",
        " \n",
        "    callbacks = myCallback()\n",
        "    \n",
        "    # Defining and Compiling the Model\n",
        "    model = tf.keras.models.Sequential([\n",
        "        # Note the input shape is the desired size of the image 150x150 with 3 bytes color\n",
        "        # This is the first convolution\n",
        "        tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),\n",
        "        tf.keras.layers.MaxPooling2D(2, 2),\n",
        "        # The second convolution\n",
        "        tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        # The third convolution\n",
        "        tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(2,2),\n",
        "        # Flatten the results to feed into a DNN\n",
        "        tf.keras.layers.Flatten(),\n",
        "        # 512 neuron hidden layer\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
        "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "            ])\n",
        "\n",
        "    from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "    model.compile(loss='binary_crossentropy',\n",
        "              optimizer=RMSprop(lr=0.001),\n",
        "              metrics=['acc'])\n",
        "        \n",
        "\n",
        "\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "    train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        '/tmp/h-or-s',  # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=10,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='binary')\n",
        "\n",
        "    # Model Fitting\n",
        "    history = model.fit(\n",
        "        train_generator,\n",
        "        steps_per_epoch=8,  \n",
        "        epochs=15,\n",
        "        verbose=1, \n",
        "        callbacks=[callbacks])\n",
        "    \n",
        "    return history.history['acc'][-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoLhdR0vs_LI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The Expected output: \"Reached 99.9% accuracy so cancelling training!\"\"\n",
        "train_happy_sad_model()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}